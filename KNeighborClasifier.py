# -*- coding: utf-8 -*-
"""KNN_Nodarse.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BivIhN-TkH6seMvkTiS2dahgctSwfny7


"""
#%%
import numpy as np
class KNN:
  def __init__(self, n_neighbor=3):
    self.n_neighbor=n_neighbor

  def fit(self, X, y):
    self.X=X
    self.y=y
  

  def predict(self, X):
    """Función que predice la salida para el dataframe de entrada

    Args:
        X: matriz de variables de entrada
    Returns:
        y_predict: Devuelve un arreglo correspondiente a las predicciones encontradas
        por cada fila de la matriz de variables de entrada
    """
    y_predict = []
    #Se recorre la matriz de variables de entrada
    for i in X:
      aux = []
      aux2 = []
      #Se recorre la matriz de entrenamiento
      for x,j in enumerate(self.X):
        #En un arreglo auxiliar se guarda la distancia euclidiana por punto y su respectivo valor en el arreglo de entrenamiento
        aux.append([np.linalg.norm(i-j), self.y[x]])
      #Se ordena el arreglo auxiliar para encontrar los vecinos más cercanos, teniendo en cuenta el numero de vecinos dado en el constructor
      aux.sort()
      menor = aux[:self.n_neighbor]
      #Se extraen solamente los valores solución de los vecinos cercanos y se valida cual valor es el que más se repite
      y_pre = np.array(menor)[:,1]
      unos = y_pre.tolist().count(1)
      ceros = len(y_pre.tolist())-unos
      if unos>ceros:
        y_predict.append(1)
      else:
        y_predict.append(0)
    return y_predict
  
  def predict_proba(self, X):
    """Función que retorna la un arreglo de arreglos donde muestra la probabilidad por cada valor de salida posible

    Args:
        X: matriz de variables de entrada
    Returns:
        y_predict_proba: Devuelve un arreglo de arreglos donde muestra la probabilidad por cada valor de salida posible

    """
    y_predict_proba = []
    #Se recorre la matriz de variables de entrada
    for i in X:
      aux = []
      aux2 = []
      #Se recorre la matriz de entrenamiento
      for x,j in enumerate(self.X):
        #En un arreglo auxiliar se guarda la distancia euclidiana por punto y su respectivo valor en el arreglo de entrenamiento
        aux.append([np.linalg.norm(i-j), self.y[x]])
      #Se ordena el arreglo auxiliar para encontrar los vecinos más cercanos, teniendo en cuenta el numero de vecinos dado en el constructor
      aux.sort()
      menor = aux[:self.n_neighbor]
      #Se extraen solamente los valores solución de los vecinos cercanos y se valida cual valor es el que más se repite
      y_pre = np.array(menor)[:,1]
      unos = y_pre.tolist().count(1)
      ceros = len(y_pre.tolist())-unos
      y_predict_proba.append([round(ceros/len(y_pre.tolist()),2), round(unos/len(y_pre.tolist()),2)])
    return y_predict_proba

X_train = np.array([[1, 1], [1, 4], [2, 3], [7, 8], [9, 9], [7, 6]]) 
X_test = np.array([[5, 4], [1, 2], [1, 3], [7, 8], [8, 9], [5, 6]]) 
y_train = [0, 0, 0, 1, 1, 1]

clf = KNN()
clf.fit(X_train, y_train)
print(clf.predict(X_test))
print(clf.predict_proba(X_test))


import matplotlib.pyplot as plt

plt.scatter(X_train[:, 0][:3], X_train[:, 1][:3], c='r')
plt.scatter(X_train[:, 0][3:], X_train[:, 1][3:], c='g')
plt.scatter(X_test[:, 0][0], X_test[:, 1][0], c='b')
plt.text(4, 3, r'y_predict=0', fontsize=10, bbox={'facecolor':'yellow', 'alpha':0.2})
plt.title("Presentación visual KNN")
plt.xlabel("X1")
plt.ylabel("X2")
plt.legend(['y=0', 'y=1', 'y(5,4)'])
plt.plot()
# %%
